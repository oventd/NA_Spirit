from db_client import MongoDBClient
from bson import ObjectId
from datetime import datetime
import pymongo

import os
import sys
utils_dir = os.path.abspath(os.path.join(os.path.abspath(__file__), "../../../"))+'/utils'
sys.path.append(utils_dir)
from logger import *
from constant import * 

class DbCrud:
    def __init__(self, logger_name=LOGGER_NAME, log_path = None):
        """
        DbCrud í´ë˜ìŠ¤ì˜ ìƒì„±ì
        - MongoDB í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ì™€ ì»¬ë ‰ì…˜ì„ ì„¤ì •í•©ë‹ˆë‹¤.
        - ë¡œê¹…ì„ ìœ„í•œ ê¸°ë³¸ ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        :param logger_name: ë¡œê±° ì´ë¦„ (ê¸°ë³¸ê°’: LOGGER_NAME)
        :param log_path: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: None, ì œê³µë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ ë¡œê·¸ ê²½ë¡œ ì‚¬ìš©)
        """
        self.db = MongoDBClient.get_db()  # ë°ì´í„°ë² ì´ìŠ¤ ê°€ì ¸ì˜¤ê¸°
        self.collection = self.db[USER_COLLECTION]  # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°

        default_log_dir = DB_LOGGER_DIR 
        if log_path is None:
            log_path = default_log_dir
        self.logger = create_logger(logger_name, log_path)

    def upsert_data(self, filter_conditions, update_fields):
        """
        ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±í•˜ê³ , ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸í•˜ëŠ” ë©”ì„œë“œ.
        :param filter_conditions: ì°¾ì„ ì¡°ê±´ (dict)
        :param update_fields: ì‚½ì… ë˜ëŠ” ì—…ë°ì´íŠ¸í•  í•„ë“œ (dict)
        :return: ì—…ë°ì´íŠ¸ ë˜ëŠ” ì‚½ì…ëœ ë¬¸ì„œì˜ ID
        """
        if not update_fields:
            raise ValueError("ì—…ë°ì´íŠ¸í•  í•„ë“œê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # ê¸°ì¡´ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        existing_document = self.collection.find_one(filter_conditions)

        if existing_document:
            # ê¸°ì¡´ ë°ì´í„°ì™€ ë”•ì…”ë„ˆë¦¬ì˜ í•„ë“œ ê°’ ë¹„êµ
            for key, value in update_fields.items():
                if existing_document.get(key) == value:
                    print(f"'{key}' í•„ë“œ ê°’ì´ ë™ì¼í•˜ë¯€ë¡œ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    update_fields.pop(key)  # ë™ì¼í•œ ê°’ì€ ì—…ë°ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°

        # ì—…ë°ì´íŠ¸í•  ë°ì´í„° ì„¤ì •
        update_data = {
            "$set": {"updated_at": datetime.utcnow()},  # ëª¨ë“  ì—…ë°ì´íŠ¸ì— ì ìš©
            "$setOnInsert": {"created_at": datetime.utcnow()}  # ìƒˆë¡œ ì‚½ì…ë  ê²½ìš° ì ìš©
        }

        # í•„ë“œ ì—…ë°ì´íŠ¸
        if update_fields:
            update_data["$set"].update(update_fields)
            update_data["$setOnInsert"].update(update_fields)

        try:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì‚½ì…, ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸
            result = self.collection.update_one(filter_conditions, update_data, upsert=True)

            if result.upserted_id:
                print(f"ìƒˆë¡œìš´ ë°ì´í„° ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.: {result.upserted_id}")
            else:
                print(f"ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸ ì™„ë£Œ: {result.modified_count} ê°œ ë¬¸ì„œ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

            return result
        except Exception as e:
            print(f"ë°ì´í„° ì—…ë°ì´íŠ¸ ë˜ëŠ” ì‚½ì… ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            return None


        
    # Read(ì¡°íšŒ ì¿¼ë¦¬ íŒŒì´í”„ë¼ì¸ ìƒì„±)
    def construct_query_pipeline(self, filter_conditions=None, sort_by=None, sort_order=None,
                                limit=0, skip=0, fields=None, user_query =None):
        """
        MongoDB ì¿¼ë¦¬ íŒŒì´í”„ë¼ì¸ì„ ìƒì„±í•˜ëŠ” ê³µí†µ í•¨ìˆ˜.
        :param filter_conditions: í•„í„° ì¡°ê±´ (ì‚¬ì „ í˜•íƒœ)
        :param sort_by: ì •ë ¬ ê¸°ì¤€ í•„ë“œ
        :param sort_order: ì •ë ¬ ìˆœì„œ (ASCENDING or DESCENDING)
        :param limit: ìµœëŒ€ ì¡°íšŒ ê°œìˆ˜
        :param skip: ê±´ë„ˆë›¸ ê°œìˆ˜
        :param fields: ë°˜í™˜í•  í•„ë“œ ëª©ë¡
        :param user_query: ê²€ìƒ‰ì–´ ê¸°ë°˜ ê²€ìƒ‰
        """
        query_filter = {}
        pipeline = []
        projection = {}

        default_sort_orders = {
            CREATED_AT: (UPDATED_AT, pymongo.DESCENDING),  # ìµœì‹ ìˆœ
            UPDATED_AT: (UPDATED_AT, pymongo.ASCENDING),  # ì˜¤ë˜ëœìˆœ
            DOWNLOADS: (DOWNLOADS, pymongo.DESCENDING),    # ë‹¤ìš´ë¡œë“œ ë§ì€ ìˆœ
        }                   

        if limit:
            pipeline.append({"$limit": limit})
        if skip:
            pipeline.append({"$skip": skip})

        if filter_conditions:
            for key, value in filter_conditions.items():
                if isinstance(value, list):
                    query_filter[key] = {"$in": value}
                else:
                    query_filter[key] = value
          
        if fields:
            for field in fields:
                if field.startswith("$"):  # í•„ë“œëª…ì´ `$`ë¡œ ì‹œì‘í•˜ë©´ ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥ì„± ìˆìŒ
                    raise ValueError(f"ERROR Invalid field name: {field}")
                projection[field] = 1
        if projection:
            pipeline.append({"$project": projection})       

        pipeline.insert(0,{"$match": query_filter})
        
        # ê²€ìƒ‰ ê¸°ëŠ¥ sort_by
        sort_conditions = {}

        if user_query is not None:
            query_filter["$text"] = {"$search": user_query}
            projection["score"]= {"$meta": "textScore"}
            
        if user_query is not None:
            query_filter["$text"] = {"$search": user_query}  # í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¡°ê±´ ì„¤ì •
            projection["score"] = {"$meta": "textScore"}  # ê²€ìƒ‰ ì ìˆ˜ í¬í•¨ (ì´ë¯¸ ì¶”ê°€ë¨)

            sort_conditions = {"textScore": -1}  # ê²€ìƒ‰ ì ìˆ˜ ìš°ì„  ì •ë ¬

            if sort_by in default_sort_orders:
                sort_by, sort_order = default_sort_orders.get(sort_by, (sort_by, pymongo.ASCENDING))
                sort_conditions[sort_by] = sort_order

            pipeline.append({"$sort": sort_conditions})  # ì •ë ¬ ì ìš©

        # ì´ì™¸ê¸°ëŠ¥ì˜ sort_by
        elif sort_by:
            sort_by, sort_order = default_sort_orders.get(sort_by, (sort_by, pymongo.ASCENDING))  # ê¸°ë³¸ê°’ ì˜¤ë¦„ì°¨ìˆœ
            pipeline.append({"$sort": {sort_by: sort_order}})
            print(f"ê¸°ë³¸ ì •ë ¬ ê¸°ì¤€ ì ìš©: {sort_by}, {sort_order}")

        self.logger.debug(f"Generated Query Pipeline: {pipeline}")  # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê¹…
        print(pipeline)
        return pipeline

    # Read(ë°ì´í„° ì¡°íšŒ)
    def find(self, filter_conditions=None, sort_by=None, sort_order=None, limit=0, skip=0, fields=None):
        """
        ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³ , í•„ìš”í•œ ê²½ìš° ì •ë ¬ ë° í•„í„°ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        :param filter_conditions: í•„í„° ì¡°ê±´ (dict ë˜ëŠ” ObjectId ë¦¬ìŠ¤íŠ¸)
        :param sort_by: ì •ë ¬ ê¸°ì¤€ í•„ë“œ
        :param sort_order: ì •ë ¬ ìˆœì„œ (ASCENDING or DESCENDING)
        :param limit: ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜
        :param skip: ê±´ë„ˆë›¸ ë°ì´í„° ê°œìˆ˜
        :param fields: ë°˜í™˜í•  í•„ë“œ ëª©ë¡
        :return: ì¡°íšŒëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        # query_filter = {}

        # if filter_conditions:
        #     if isinstance(filter_conditions, list):
        #         object_ids = []
        #         for value in filter_conditions:
        #             if isinstance(value, str):  # ë¬¸ìì—´ì´ë©´ ObjectIdë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        #                 try:
        #                     object_ids.append(ObjectId(value))
        #                 except Exception:
        #                     raise ValueError(f"Invalid ObjectId format: {value}")
        #             elif isinstance(value, ObjectId):  # ì´ë¯¸ ObjectIdì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        #                 object_ids.append(value)
        #         if object_ids:
        #             query_filter["_id"] = {"$in": object_ids}
        #     elif isinstance(filter_conditions, dict):
        #         query_filter.update(filter_conditions)

        # pipeline = self.construct_query_pipeline(query_filter, sort_by, sort_order, limit, skip, fields)

        # result = list(self.collection.aggregate(pipeline))
        # self.logger.info(f"Query executed with filter: {filter_conditions} | Found: {len(result)} documents")
        
        query_filter = {}

        if isinstance(filter_conditions, list):
            object_ids = []
            for value in filter_conditions:
                if isinstance(value, str):
                    object_ids.append(ObjectId(value))  # ë¬¸ìì—´ì´ë©´ ObjectIdë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
                elif isinstance(value, ObjectId):
                    object_ids.append(value)
            query_filter["_id"] = {"$in": object_ids}

        elif isinstance(filter_conditions, dict):
            query_filter.update(filter_conditions)  

        pipeline = self.construct_query_pipeline(query_filter, sort_by, sort_order, limit, skip, fields)

        result = list(self.collection.aggregate(pipeline))
        self.logger.info(f"Query executed with filter: {filter_conditions} | Found: {len(result)} documents")
        return result
    
    def find_one(self, object_id, fields=None):
        """
        ìì‚°ì˜ ê³ ìœ  IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìì‚°ì„ ì¡°íšŒí•˜ì—¬ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜
        :param object_id: ìì‚°ì˜ ê³ ìœ  ID
        :param fields: ë°˜í™˜í•  í•„ë“œ ëª©ë¡ (ê¸°ë³¸ê°’ì€ None, íŠ¹ì • í•„ë“œë§Œ ë°˜í™˜)
        :return: ìì‚°ì˜ ìƒì„¸ ì •ë³´ (object_id, asset_type, description, price ë“±)
        """
        projection = None

        if fields:
            projection = {}
            for field in fields:
                projection[field] = 1

        # ìì‚° IDë¡œ ì¿¼ë¦¬
        query_filter = {OBJECT_ID: ObjectId(object_id)}  # ObjectIdë¡œ ë³€í™˜
        print(f"Query Filter (ID): {query_filter} | Projection Fields: {projection}")
        
        details = self.collection.find_one(query_filter, projection)
        self.logger.info(f"Retrieved document ID: {object_id} | Document Details: {details}")
        return details
    
    def search(self, filter_conditions=None, limit=0, skip=0, fields=None, sort_by=None, sort_order=None, user_query = None):
        """
        ê²€ìƒ‰ì–´ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¡°íšŒ. ê²€ìƒ‰ ì ìˆ˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ë¨.
        :param user_query: ì‚¬ìš©ì ê²€ìƒ‰ì–´
        :param filter_conditions: í•„í„° ì¡°ê±´ (ì‚¬ì „ í˜•íƒœ)
        :param limit: ì¡°íšŒí•  ë°ì´í„° ê°œìˆ˜ ì œí•œ
        :param skip: ê±´ë„ˆë›¸ ë°ì´í„° ê°œìˆ˜
        :param fields: ë°˜í™˜í•  í•„ë“œ ëª©ë¡
        :param sort_by: ì •ë ¬ ê¸°ì¤€ í•„ë“œ
        :param sort_order: ì •ë ¬ ìˆœì„œ
        :return: ê²€ìƒ‰ëœ ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸
        """
        if fields == None:
            fields = SEARCH_FIELDS

        pipeline = self.construct_query_pipeline(filter_conditions, sort_by, sort_order, limit, skip, fields, user_query=user_query)

        # ê²°ê³¼ ë°˜í™˜
        result = list(self.collection.aggregate(pipeline))
        self.logger.info(f"Search executed with query: {user_query} | Found: {len(result)} documents")
        return result

    # Update(ë‹¤ìš´ë¡œë“œ ìˆ˜ ì¦ê°€)
    def increment_count(self, object_id, field):
        """
        ìì‚°ì˜ ë‹¤ìš´ë¡œë“œ ìˆ˜ë¥¼ ì¦ê°€ì‹œí‚µë‹ˆë‹¤.
        :param object_id: ë‹¤ìš´ë¡œë“œ ìˆ˜ë¥¼ ì¦ê°€ì‹œí‚¬ ìì‚°ì˜ ID
        :return: ë‹¤ìš´ë¡œë“œ ìˆ˜ ì¦ê°€ ì—¬ë¶€ (True/False)
        """
        result = self.collection.update_one(
            {OBJECT_ID: ObjectId(object_id)},
            {"$inc": {field: 1}},
            upsert=False
        )
        self.logger.info(f"Incremented download count for document ID: {object_id}")
        return result.modified_count > 0  

    # Delete(ë°ì´í„° ì‚­ì œ)
    def delete_one(self, object_id):
        """
        ìì‚°ì„ ì‚­ì œí•©ë‹ˆë‹¤.
        :param object_id: ì‚­ì œí•  ìì‚°ì˜ ID
        :return: ì‚­ì œ ì„±ê³µ ì—¬ë¶€ (True/False)
        """
        result = self.collection.delete_one({OBJECT_ID: ObjectId(object_id)})  # ìì‚° IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì‚­ì œ
        self.logger.info(f"Deleted document ID: {object_id} | Acknowledged: {result.acknowledged}")
        return result.acknowledged


# Spiritì—ì„œ êµ¬í˜„ë˜ëŠ” í´ë˜ìŠ¤(ìì‹ í´ë˜ìŠ¤)
class AssetDb(DbCrud):
    def __init__(self, log_path=None):
        super().__init__(ASSET_LOGGER_NAME, ASSET_LOGGER_DIR)  # ë¶€ëª¨ í´ë˜ìŠ¤ì˜ ìƒì„±ì í˜¸ì¶œ
        self.setup_indexes()

    def setup_indexes(self):
            """ìì‚° ì»¬ë ‰ì…˜ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì„¤ì •"""
            # self.asset_collection.create_index([(FILE_FORMAT, pymongo.ASCENDING)])
            # self.asset_collection.create_index([(UPDATED_AT, pymongo.DESCENDING)])
            # self.asset_collection.create_index([(UPDATED_AT, pymongo.ASCENDING)])
            # self.asset_collection.create_index([(DOWNLOADS, pymongo.DESCENDING)])
            # self.asset_collection.create_index(
            #     [(NAME, "text")]
            #     # weights={NAME: 10, DESCRIPTION: 1}  # 'name' í•„ë“œì— 10, 'description' í•„ë“œì— 1ì˜ ê°€ì¤‘ì¹˜ ë¶€ì—¬
            # )
            # ë³µí•© ì¸ë±ìŠ¤ ìƒì„± (ìì‹ í´ë˜ìŠ¤ì—ì„œ í•œ ë²ˆë§Œ ì‹¤í–‰)
            # self.asset_collection.create_index(
            #     [("project_name", pymongo.ASCENDING), ("name", pymongo.ASCENDING)], 
            #     unique=True)
            # self.logger.info("Indexes set up for AssetDb")

    def upsert_asset(self, namespace_name, update_fields=None):
        """
        ì—ì…‹ì´ ì—†ìœ¼ë©´ ìƒì„±í•˜ê³ , ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸.
        :param namespace_name: í”„ë¡œì íŠ¸ ì´ë¦„
        :param update_fields: ì—…ë°ì´íŠ¸í•  í•„ë“œ (ì„ íƒ ì‚¬í•­)
        """
        existing_asset = self.find_asset(namespace_name)  # ë¨¼ì € ì¡°íšŒ

        filter_query = {"namespace": namespace_name}
        update_data = {}

        if existing_asset:
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸ë§Œ ìˆ˜í–‰
            update_data["$set"] = {"updated_at": datetime.utcnow()}  # ë³€ê²½ ì‹œê°„ ê°±ì‹ 

            if update_fields:
                # ë™ì¼í•œ ê°’ì€ ì—…ë°ì´íŠ¸ì—ì„œ ì œê±°
                for key, value in update_fields.items():
                    if existing_asset.get(key) == value:
                        print(f"'{key}' í•„ë“œ ê°’ì´ ë™ì¼í•˜ë¯€ë¡œ ì—…ë°ì´íŠ¸í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                        update_fields.pop(key)  # ë™ì¼í•œ ê°’ì€ ì—…ë°ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ì—ì„œ ì œê±°
                # ì—…ë°ì´íŠ¸ í•„ë“œ ì ìš©
                update_data["$set"].update(update_fields)

            result = self.collection.update_one(filter_query, update_data, upsert=False)
            print(f"âœ… ê¸°ì¡´ ì—ì…‹ ì—…ë°ì´íŠ¸ ì™„ë£Œ")

        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
            new_data = {
                "namespace": namespace_name,
                "created_at": datetime.utcnow(),  # ìµœì´ˆ ìƒì„± ì‹œê°„ ì¶”ê°€
                "updated_at": datetime.utcnow()
            }
            if update_fields:
                new_data.update(update_fields)

            result = self.collection.update_one(filter_query, {"$set": new_data}, upsert=True)
            print(f"âœ… ìƒˆë¡œìš´ ì—ì…‹ ìƒì„±: {result.upserted_id}")

    def find_asset(self, namespace_name, fields=None):
        """
        íŠ¹ì • í”„ë¡œì íŠ¸ì˜ ì—ì…‹ ë°ì´í„°ë¥¼ ì¡°íšŒí•œë‹¤.
        :param namespace_name: í”„ë¡œì íŠ¸ ì´ë¦„
        :param fields: ì„ íƒì ìœ¼ë¡œ ë°˜í™˜í•  í•„ë“œ ëª©ë¡
        :return: ì¡°íšŒëœ ë°ì´í„° ë˜ëŠ” None
        """
        filter_query = {"namespace": namespace_name}

        projection = {field: 1 for field in fields} if fields else None  # í•„ìš”í•œ í•„ë“œë§Œ ì¡°íšŒ

        asset = self.collection.find_one(filter_query, projection)

        if asset:
            print(f"ğŸ” ì¡°íšŒëœ ë°ì´í„°: {asset}")
        else:
            print("âŒ í•´ë‹¹ ì—ì…‹ ë°ì´í„° ì—†ìŒ")

        return asset

if __name__ == "__main__":
    db = DbCrud()
    